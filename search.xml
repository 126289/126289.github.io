<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>2022-10-21softmax回归</title>
      <link href="/2023/03/01/2022-10-21-tu-xiang-fen-lei-shu-ju-ji/"/>
      <url>/2023/03/01/2022-10-21-tu-xiang-fen-lei-shu-ju-ji/</url>
      
        <content type="html"><![CDATA[<h3 id="实现softmax的三个步骤："><a href="#实现softmax的三个步骤：" class="headerlink" title="实现softmax的三个步骤："></a>实现softmax的三个步骤：</h3><p>1.对每个项求幂（使用exp)<br>2.对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数<br>3.将每一行除以其规范化常数，确保结果的和为1</p><h3 id="torch-normal-的用法"><a href="#torch-normal-的用法" class="headerlink" title="torch.normal()的用法:"></a>torch.normal()的用法:</h3><pre><code class="javascript">torch.normal(means, std, out=None)</code></pre><p>返回一个张量，包含从给定参数means,std的离散正态分布中抽取随机数。 均值means是一个张量，包含每个输出元素相关的正态分布的均值。 std是一个张量，包含每个输出元素相关的正态分布的标准差。 均值和标准差的形状不须匹配，但每个张量的元素个数须相同。<br>参数:<br>means (Tensor) – 均值<br>std (Tensor) – 标准差<br>out (Tensor) – 可选的输出张量</p><h3 id="reshape函数参数-1-X-reshape-X-shape-0-1-T"><a href="#reshape函数参数-1-X-reshape-X-shape-0-1-T" class="headerlink" title="reshape函数参数-1(X.reshape(X.shape[0], -1).T):"></a>reshape函数参数-1(X.reshape(X.shape[0], -1).T):</h3><p> X.reshape(X.shape[0], -1).T可以将一个维度为(a,b,c,d)的矩阵转换为一个维度为(b∗c∗d, a)的矩阵。<br> 我们假设x的shape是(209, 64, 64, 3)的,然后我们说shape[0]就是第一个列的行数,也就是209<br> 通过reshape重新建立维度，第一个维度就是X.shape[0]，这就是正常的reshape操作；第二个维度是-1，我们知道X的shape属性是多少，是(209, 64, 64, 3)，但是想让X变成209行，列数不知道是多少，所以也就是209 * 64 * 64 * 3 / 209，也就是64 * 64 * 3<br>总结一下，参数-1就是不知道行数或者列数多少的情况下使用的参数，所以先确定除了参数-1之外的其他参数，然后通过(总参数的计算) / (确定除了参数-1之外的其他参数) = 该位置应该是多少的参数。 </p>]]></content>
      
      
      <categories>
          
          <category> /小书匠/日记/2022-10 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-10-21线性回归</title>
      <link href="/2023/03/01/2022-10-21-xian-xing-hui-gui/"/>
      <url>/2023/03/01/2022-10-21-xian-xing-hui-gui/</url>
      
        <content type="html"><![CDATA[<h3 id="存储梯度："><a href="#存储梯度：" class="headerlink" title="存储梯度："></a>存储梯度：</h3><pre><code class="javascript">x.requires_grad(True) //等价于x=torch.arange(4.0,requires_grad=True)x.grad  // 默认值是None</code></pre><p>requires_grad是Pytorch中通用数据结构Tensor的一个属性，用于说明当前量是否需要在计算中保留对应的梯度信息</p><h3 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h3><pre><code class="javascript">true_w = torch.tensor([2, -3.4])true_b = torch.tensor(4.2)features, labels = d2l.synthetic_data(true_w, true_b, 1000)</code></pre><p>synthetic_data函数说明<br>这里也可以用d2l.synthetic_data？或者d2l.synthetic_data？？来查询函数相关信息<br>如果用两个问号，可以查看函数的具体实现代码</p><pre><code class="javascript">help(d2l.synthetic_data)</code></pre><h3 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h3><p>🎋第一步：导包 </p><pre><code class="javascript">import torchimport randomfrom d2l import torch as d2l</code></pre><p>若显示报错，没有d2l这个模块，在jupyter notebook中输入</p><pre><code class="javascript">!pip install -U d2l </code></pre><p>🎋第二步：构造函数</p><pre><code class="javascript">def synthetic_data(w,b,num_examples):    '''生成y = wx + b + 噪声。  '''    x = torch.normal(0,1,(num_examples,len(w)))    y = torch.matmul(x,w) + b    y += torch.normal(0,0.01,y.shape)    return x,y.reshape((-1,1))true_w = torch.tensor([2,-3.4])true_b = 4.2features,labels = synthetic_data(true_w,true_b,1000)print("features:",features[0],"\nlabels:",labels[0])</code></pre><p>1)此处b是个一维向量，当matmul的第一个参数是2维向量，第2个参数是一维向量时，返回的是矩阵和向量的乘积，结果是向量，因此，y需要reshape</p><p>2）reshape中-1表示自动计算，1表示固定，即列向量为1</p><p>3）创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。</p><p>normal(0, 1, size=(3, 4))<br>🎋结果<br><img src="/./images/d13270b7a3034c0f90caf16bf7f8a9c5.png" alt="enter description here"><br>🎋第三步：画图看一下是不是线性相关</p><pre><code class="javascript">d2l.set_figsize()d2l.plt.scatter(features[:,-1].detach().numpy(),labels.detach().numpy(),1)</code></pre><p>1）detach()分离出数值，不再含有梯度</p><p>2）scatter()函数最后的一个1是绘制点直径的大小，如果改成50会看到一个个点非常粗</p><p>3）总的来说 生成第二个特征features[:, 1]和labels的散点图， 可以直观观察到两者之间的线性关系</p><h3 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h3><p>🎋第一步：定义函数<br> 训练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。 由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数， 该函数能打乱数据集中的样本并以小批量方式获取数据。</p><p>在下面的代码中，我们定义一个data_iter函数， 该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为batch_size的小批量。 每个小批量包含一组特征和标签</p><pre><code class="javascript">def data_iter(batch_size,features,labels):    num_examples = len(features)    indices = list(range(num_examples))    random.shuffle(indices)    for i in range(0,num_examples,batch_size):        batch_indices = torch.tensor(        indices[i:min(i+batch_size,num_examples)])        yield features[batch_indices],labels[batch_indices]</code></pre><p>1)只是indices这个list被打乱了，features和labels都是顺序的，用循环才能随机地放进去</p><p>2)min的作用：不让访问越界    list超出会报错，out of index</p><p>3）通过 yield，创建生成器，我们不再需要编写读文件的迭代类，就可以轻松实现文件读取<br>🎋第二步：感受一下小批量运算<br>我们直观感受一下小批量运算：读取第一个小批量数据样本并打印。 每个批量的特征维度显示批量大小和输入特征数。 同样的，批量的标签形状与batch_size相等</p><pre><code class="javascript">batch_size = 10for X, y in data_iter(batch_size, features, labels):    print(X, '\n', y)    break</code></pre><p><img src="/./images/9a6669ea4439421ba4460a85f884113f.png" alt="enter description here"><br>🎄 初始化模型参数<br>通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0</p><pre><code class="javascript">w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)b = torch.zeros(1, requires_grad=True)</code></pre><p>1）计算梯度<br>作用在于更新参数</p><pre><code class="javascript">requires_grad=True</code></pre><p>2）b为偏置   偏置初始化为0</p><p>🎄 定义模型</p><pre><code class="javascript">def linreg(X, w, b):  #@save    """线性回归模型"""    return torch.matmul(X, w) + b</code></pre><p>1）torch.matmul(X, w)   矩阵乘以向量  等于 向量</p><p>2）b是标量</p><p>根据广播机制： 当我们用一个向量加一个标量时，标量会被加到向量的每个分量上</p><p>🎄定义损失函数 </p><pre><code class="javascript">def squared_loss(y_hat, y):  #@save    """均方损失"""    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2</code></pre><p>1）均方损失为：预测值y_hat 减去y真实值的平方除以2</p><p>2）而且需要将真实值y的形状转换为和预测值y_hat的形状相同</p><p>🎄定义优化算法<br>小批量随机梯度下降。</p><p>在每一步中，使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度。 接下来，朝着减少损失的方向更新我们的参数。</p><p>下面的函数实现小批量随机梯度下降更新。 该函数接受模型参数集合、学习速率和批量大小作为输入。</p><p>每 一步更新的大小由学习速率lr决定。 因为我们计算的损失是一个批量样本的总和，所以我们用批量大小（batch_size） 来规范化步长，这样步长大小就不会取决于我们对批量大小的选择。</p><pre><code class="javascript">def sgd(params, lr, batch_size):  #@save    """小批量随机梯度下降"""    with torch.no_grad():        for param in params:            param -= lr * param.grad / batch_size            param.grad.zero_()</code></pre><p>1）with torch.no_grad():</p><p>更新时不要计算梯度</p><p>2）param.grad.zero_()</p><p>pytorch会不断的累加变量的梯度，所以每更新一次参数，就要让其对应的梯度清零 </p><p>3）for param in params:</p><p>对每个参数进行计算（可能是w,可能是b）</p><p>4)不除以batch_size损失函数就是平方和误差<br>我们只要误差就行了</p><p>🎄训练<br>现在我们已经准备好了模型训练所有需要的要素，可以实现主要的训练过程部分了。</p><p>理解这段代码至关重要，因为从事深度学习后， 你会一遍又一遍地看到几乎相同的训练过程。</p><p>在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。 计算完损失后，我们开始反向传播，存储每个参数的梯度。</p><p>最后，我们调用优化算法sgd来更新模型参数。<br><img src="/./images/f10c2d0325d1499d8f8e23e043cc05d5.png" alt="enter description here"></p><p>在每个迭代周期（epoch）中，我们使用data_iter函数遍历整个数据集， 并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。 这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设为3和0.03。 设置超参数很棘手，需要通过反复试验进行调整。 </p><pre><code class="javascript">lr = 0.03num_epochs = 3net = linregloss = squared_loss for epoch in range(num_epochs):    for X,y in data_iter(batch_size,features,labels):        l = loss(net(X,w,b),y) #X和y的小批量损失        #因为L形状是（batch_size,1）而不是一个标量。L中的所有元素加到一起，        #并因此计算[w,b]梯度        l.sum().backward()        sgd([w,b],lr,batch_size) #使用参数的梯度更新参数    with torch.no_grad():        train_1 = loss(net(features,w,b),labels)        print(f'epoch {epoch+1},loss {float(train_1.mean())}:f')</code></pre><p>1）这里用net是指的线性模型，用net因为后面深度学习网络层数相关 </p><p>如果你没有linreg你会报错<br><img src="/./images/32b3fe6c80ad4f7fa422b7be729be801.png" alt="enter description here"><br>2）l.sum().backward()<br>求和目的：</p><p>之前自动求导那节讲到了向量求梯度比较麻烦 都通过sum()转化为标量再求梯度</p><p>求和之后后面会除batch_size，可以计算均值</p><p>求和本身让l以标量的形式表现出来。所有的梯度也叠加了嘛，所以sgd里面除了batch_size</p><p>它会返回每个epoch的损失 ，看到loss在减少<br><img src="/./images/b7d591ae4d2e44c8a8a5ac9c6bedfa2a.png" alt="enter description here"><br> 打印一下w 和 b 的误差</p><pre><code class="javascript">print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')print(f'b的估计误差: {true_b - b}')</code></pre><p><img src="/./images/f10bb3991ee14d39bf38f49267870bec.png" alt="enter description here"></p>]]></content>
      
      
      <categories>
          
          <category> /小书匠/日记/2022-10 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>天池图像识别</title>
      <link href="/2020/01/14/tianchituxian/"/>
      <url>/2020/01/14/tianchituxian/</url>
      
        <content type="html"><![CDATA[<h3 id="代码使用"><a href="#代码使用" class="headerlink" title="代码使用"></a>代码使用</h3><ul><li>data文件夹<br><ul><li>mchar文件夹<br><br>  mchar文件夹用来存放数据集，数据集从天池官网进行下载。</li><li>dataset.py<br><br>  继承data.DataSet，构建适合SVHN数据集的类SVHMDataset。</li></ul></li><li>mode文件夹<br><ul><li>basic_model.py<br><br>  构建神经网络模型，在ResNet18或ResNet34后面并联4个全连接层用于分类。<br><br>  也可以构建自己的模型或使用更复杂的模型。</li></ul></li><li>main.py<br><ul><li>train_val()<br><br>  训练和验证</li></ul><pre><code class="python">python main.py train_val</code></pre><ul><li>test_submit()<br><br>  测试和提交</li></ul><pre><code class="python">python main.py test_submit --path = 'checkpoints/...'</code></pre></li><li>utils<br><br>用于存放各种工具函数。</li><li>checkpoints<br><br>用于存放训练的模型。</li></ul><h3 id="实践总结"><a href="#实践总结" class="headerlink" title="实践总结"></a>实践总结</h3><p>这次实践是天池上的一个字符识别比赛mchar，数据集使用的是Google街景图像门牌号数据集SVHM，任务是识别不定长街景门牌字符。  </p><p>解决这个问题的思路可以有多种。一是当作<strong>图像分类</strong>问题，首先固定字符的长度，然后在CNN后添加多个全连接分支进行多字符分类，按顺序把多个分支的结果连接，作为最终的结果输出。二是当作<strong>目标检测</strong>问题，首先检测出每张图片中的多个字符，然后按顺序把字符连接起来，作为最终的结果输出。  </p><p>master分支中实现的是图像分类的解决思路，SSD分支中实现的是SSD目标检测的解决思路。</p><h3 id="baseline图像分类"><a href="#baseline图像分类" class="headerlink" title="baseline图像分类"></a>baseline图像分类</h3><p>这个比赛给了一个baseline基础代码，格式是jupyter notebook。我把整个代码改为了pycharm工程的格式。<br><br>整体提交的结果如下：<br><img alt="整体提交score.PNG" src="assets/整体提交score.PNG" width="300" height=""></p><p>第一次按照baseline进行训练，batch_size=40，epoch=10，提交的结果是score=0.3396，是比较低的。<br><br>我们发现baseline中训练集和验证集图片的处理是resize成(64,128)，然后随机裁剪为(60,120)。但是测试集图片处理是resize为(70,140)。<br><br>由于训练模型适应的图片尺寸和测试集输入的图片尺寸不符，尺寸偏差不大，但是了超过10%，而我们这个任务对于字符位置是很敏感的，造成最终测试集得分比较低。修改这个baseline中的bug后，后续的测试集得分就比较高了。</p><h3 id="ResNet18-学习率调节"><a href="#ResNet18-学习率调节" class="headerlink" title="ResNet18 学习率调节"></a>ResNet18 学习率调节</h3><p>baseline中使用的是Pytorch中ResNet18的预训练模型。我们就在这个模型上进行调节。</p><ul><li><p><strong>一阶学习率</strong></p><ul><li><p><strong>lr = 0.01</strong><br><br><img alt="mchar-学习率0.01.bmp" src="assets/mchar-学习率0.01.bmp" width="700" height=""><br><br>我们整个基于图片分类的解决方案中使用的优化器都是Adam。<br><br>首先以0.01的学习率训练了10个epoch，我们发现起始的val_loss没有快速的下降，val_acc没有快速提高，都处于波动。说明初始初始学习率0.01不合适。<br><br>尽管初始学习率设置为0.01不合适，但是我们还是看到在10个epoch后，val_acc提高到0.4104，见证了<strong>Adam优化器的强大</strong>。Adam优化器兼具AdaDelta和动量的优点。AdaDelta优化器的学习率是随时间和参数变化的，从而减少了手动调节学习率，所以Adam在初始学习率0.01不合适的情况下，在自适应调节了3个epoch后，我们看到val_acc的快速上升。由于加入了动量项，所以Adam优化器可以加速收敛，减小振荡。  </p></li><li><p><strong>lr = 0.001</strong><br><br>  <img alt="mchar-学习率0.001.bmp" src="assets/mchar-学习率0.001.bmp" width="700" height=""><br><br>  这是以0.001作为初始学习率训练15个epoch的结果。我们看到开始的val_loss在快速下降，val_acc在快速上升，8个epoch之后就将val_acc提高到0.5612。说明<strong>0.001的初始学习率是合适的</strong>。<br><br>  第9个epoch到第14个epoch，val_loss在1.85到2.91之间大幅度波动，val_acc在0.5175到0.5717之间大幅度波动。说明这个<strong>学习率太大，导致在极小值附近波动，无法收敛</strong>。此时考虑引入二阶段更小的学习率。</p></li></ul></li><li><p><strong>二阶学习率</strong></p><ul><li><strong>lr = 0.0001</strong><br><br>  <img alt="mchar-0.001+0.0001.bmp" src="assets/mchar-0.001+0.0001.bmp" width="700" height=""><br><br>  初始学习率设置为0.001，第5个epoch后，调节学习率降低为原来的10%，为0.0001，然后继续训练15个epoch。<br><br>  在第5个epoch后，val_loss从3.11大幅降低到2.33，val_acc从0.5128大幅提高到0.589。我们看到了<strong>学习率阶段下降的效果很好</strong>。<br><br>  但是第10个epoch后，val_loss开始逐渐增大，出现了<strong>过拟合现象</strong>。</li></ul>  <img alt="mchar-val_loss.svg" src="assets/mchar-lossacc/0.001+0.0001/val_loss.svg" width="350" height="">  <img alt="mchar-val_acc.svg" src="assets/mchar-lossacc/0.001+0.0001/val_acc.svg" width="350" height=""><br>  训练集的loss是在不断下降的，val_loss先减小后增大（左图）（横坐标标错了，实际是epoch，图中标注的是iter），val_acc先上升然后波动（右图）。这是典型的过拟合现象。<br>  过拟合的处理方法：<br>  （1）增大数据集的样本数量。<br>  （2）数据增强，对图像进行丰富的变换或添加噪声。<br>  （3）正则化。损失函数添加正则化项来惩罚模型参数。<br>  （4）Dropout或BN层。早期一般在全连接网络中使用Dropout，现在一般在卷积网络中使用BN层。<br>  （5）减小学习率。<br>  下面使用各种方法抑制过拟合现象。<br><ul><li><strong>正则化-抑制过拟合</strong><br><br>  <img alt="mchar-0.001+0.0001+weight.bmp" src="assets/mchar-0.001+0.0001+weight.bmp" width="700" height=""><br><br>  初始学习率是0.001，训练5个epoch后，学习率降低为原来的10%，为0.0001，然后继续训练15个epoch。依然在第5个epoch后，看到val_loss从2.28降低到1.99，val_acc从0.502大幅提升到0.5899。<br></li></ul><p>  这里Adam优化器加入了weight_decay=0.0005。baseline中的Adam优化器weight_decay默认值是0。<br><br>  <img alt="mchar-val_loss.svg" src="assets/mchar-lossacc/0.001+0.0001+weight_decay/val_loss.svg" width="350" height=""><br>  <img alt="mchar-val_loss.svg" src="assets/mchar-lossacc/0.001+0.0001+weight_decay/val_acc.svg" width="350" height=""><br><br>  左图是val_loss，右图是val_acc。可以看到有抑制过拟合的效果，且val_acc提高了一个点。没有加正则化项前，val_acc稳定在0.59，现在从第8个epoch到最后一个epoch，val_acc稳定在0.60级别。</p></li><li><p><strong>三阶学习率</strong><br></p><ul><li><strong>lr = 0.00001</strong><br><br>  <img alt="mchar-三阶段学习率0.1.bmp" src="assets/mchar-三阶段学习率0.1.bmp" width="700" height=""><br><br>  初始学习率是0.001，在第5个epoch后，学习率降低为前一个的10%，为0.0001，在第10个epoch后，学习率降低为前一个的10%，为0.00001。<br></li></ul>  <img alt="assets/mchar-lossacc/三阶段0.1/val_loss.svg" src="assets/mchar-lossacc/三阶段0.1/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/三阶段0.1/val_acc.svg" src="assets/mchar-lossacc/三阶段0.1/val_acc.svg" width="350" height=""><br>  左图为val_loss，右图为val_acc。可以看到降低学习率，进一步抑制过拟合的效果。但是最后val_acc还是稳定在0.60级别，没有带来验证集精度的提升。<br>  我还尝试了将三阶段的学习率调节为二阶段学习率的0.2，0.05，0.01，都可以起到抑制过拟合的效果，但是val_acc都是稳定在0.60级别，没有涨点。</li><li><p><strong>小结</strong>  </p><ul><li>三阶学习率阶梯下降是十分有效的。<br><br>  第二阶段的学习率的下降，可以大幅降低val_loss，大幅提高val_acc。第三阶段的学习率的下降，可以稳定val_loss，进一步缓慢的提高一点val_acc。<br><br>  在下面的其他模型/其他任务实验中，我们会继续看到使用三阶段学习率的效果很好。<br><br>  SSD分支中使用的是SGD优化器，同样设置了2个节点，来降低学习率为前一个学习率的10%，从而构成三阶段学习率阶梯下降。<br><br>  一般设置第一阶段的学习率是0.001，第二个阶段是0.0001，第三个阶段是0.00001。</li><li>Adam优化器很强大。下面实验都是使用Adam优化器+三阶段学习率。<br><br>  一个精细调节的SGD优化器在最终的收敛效果上可以略微超过Adam优化器，但是Adam优化器对初始学习率的设置容错度较高，可以自适应调节学习率。Adam优化器比SGD收敛更快。</li><li>当训练epoch太多时，容易出现过拟合。<br><br>  可以通过数据增强、添加正则化项、Dropout或BN层、减小学习率等来抑制过拟合。<br><br>  上面已经看到正则化抑制过拟合的效果，并涨了一个点。 减小学习率也可以一定程度抑制过拟合，但是这个实验没有精度的提高。<br><br>  BN层的效果比Dropout好一些，早期的网络使用的是Dropout，ResNet中使用的是BN层，且BN层和Dropout同时使用效果不好。<br></li></ul><p>  下面将从数据增强角度来抑制过拟合，并期望进一步提高val_acc精度。</p></li></ul><h3 id="ResNet18-数据增强"><a href="#ResNet18-数据增强" class="headerlink" title="ResNet18 数据增强"></a>ResNet18 数据增强</h3><p>baseline中训练集的数据增强是先resize到(64,128)，然后随机裁剪为(60,120)。验证集和测试集没有数据增强，只是resize到(60,120)。<br><br>随机裁剪已经是一个十分有效的数据增强手段，下面进行其他的数据增强。<br></p><p>数据读取、显示、变换和处理可以使用的库有matplotlib、OpenCV、skimage和Pytorch中的torchvision等。</p><ul><li><p><strong>光学变换</strong><br><br>使用的是torchvision.transform中的ColorJitter()，随机调节图片的亮度、对比度、饱和度和色调。使得模型适应不同的亮度、对比度、饱和度和色调下的图片中的字符识别。</p></li><li><p><strong>噪声</strong></p><ul><li><p><strong>椒盐噪声</strong><br><br>  我们采用的是skimage库的randon_noise添加椒盐噪声。<br></p>  <img alt="mchar-23.PNG" src="assets/mchar-23.PNG" width="350" height="">  <img alt="mchar-23_ps.PNG" src="assets/mchar-23_ps.PNG" width="350" height=""><br>  左图是原图，右图是添加椒盐噪声后的图片。<br>  <img alt="mcharlog/椒盐噪声.bmp" src="assets/mchar-log/椒盐噪声.bmp" width="700" height=""><br>  添加椒盐噪声后，增大了学习难度，最后val_acc在0.56-0.57之间波动。<br>  <img alt="assets/mchar-lossacc/椒盐噪声/val_loss.svg" src="assets/mchar-lossacc/椒盐噪声/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/椒盐噪声/val_acc.svg" src="assets/mchar-lossacc/椒盐噪声/val_acc.svg" width="350" height=""><br>  我们发现添加噪声虽然可以起到数据增强的效果，抑制过拟合。但是同时增大了学习的难度，而且椒盐噪声对于这个字符识别任务是没有太明显的作用。</li><li><p><strong>高斯噪声</strong><br><br>  依然采用skimage库中的random_noise添加高斯噪声。<br></p>  <img alt="mchar-23.PNG" src="assets/23.PNG" width="350" height="">  <img alt="mchar-23_gaussian.PNG" src="assets/23_gaussian.PNG" width="350" height=""><br>  左图是原图，右图是添加高斯噪声后图片。高斯噪声是对整个图片添加服从高斯分布的噪声，比较均匀，最后的效果看起来比较模糊。椒盐噪声分布不均匀，呈现颗粒状，且强度大。<br>  <img alt="mcharlog/椒盐噪声.bmp" src="assets/mchar-log/高斯噪声.bmp" width="700" height=""><br>  添加高斯噪声也会增加学习的难度，但是没有椒盐噪声的强度大，最后val_acc稳定在0.59。<br>  <img alt="assets/mchar-lossacc/高斯噪声/val_loss.svg" src="assets/mchar-lossacc/高斯噪声/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/高斯噪声/val_acc.svg" src="assets/mchar-lossacc/高斯噪声/val_acc.svg" width="350" height=""><br>  高斯噪声的val_loss最后的波动幅度比较小，val_acc比椒盐噪声高2个点。我们认为高斯噪声带来的模糊效果是符合这个字符识别数据集的，因为数据集中的部分图片分辨率低，高斯噪声降低分辨率可以使得模型更好的适应低分辨率图片下的字符识别。<br>  因此，下面没有使用添加噪声，而是直接进行了图像模糊处理。</li><li><p><strong>图像模糊</strong><br></p>  <img alt="mchar-23.PNG" src="assets/23.PNG" width="350" height="">  <img alt="mchar-23_gaussian.PNG" src="assets/23_blur.PNG" width="350" height=""><br>  左图是原图，右图是模糊处理后的图片。<br>  <img alt="assets/000005.PNG" src="assets/000005.png" width="233" height="">  <img alt="assets/000021.PNG" src="assets/000021.png" width="233" height="">  <img alt="assets/000079.PNG" src="assets/000079.png" width="233" height=""><br>  这是挑选的数据集中的几张分辨率低的图片，对图片进行模糊处理可以达到类似的效果。<br>  <img alt="mcharlog/图像模糊.bmp" src="assets/mchar-log/图像模糊.bmp" width="700" height=""><br>  图像模糊处理会增加学习难度，抑制过拟合，且符合该学习任务的数据集低分辨率特点。<br>  <img alt="assets/mchar-lossacc/图像模糊/val_loss.svg" src="assets/mchar-lossacc/图像模糊/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/图像模糊/val_acc.svg" src="assets/mchar-lossacc/图像模糊/val_acc.svg" width="350" height=""><br>  val_loss最终的波动幅度较小，val_acc稳定在0.59级别。<br>  通过对比上面三种添加噪声的方法，图像模糊最符合该任务中数据集图片特点，可以使得模型适应低分辨率图片下的字符识别。学习难度和高斯噪声相当，低于椒盐噪声。椒盐噪声可以起到数据增强的效果，但是对该任务没有明显的针对作用。<br></li></ul></li><li><p><strong>几何变换</strong></p><ul><li><p><strong>镜像</strong><br><br>  随机左右镜像和上下镜像是十分有效的数据增强手段，例如可以使用torchvision中的RandomHorizontalFlip()等。镜像可以使得模型适应不同位置，不同形态下的物体分类和识别。<br><br>  但是，该学习任务是数字字符串识别，<strong>不可以使用镜像处理</strong>。</p></li><li><p><strong>旋转</strong><br><br>  随机角度旋转也是有效的数据增强手段，且该学习任务的数据集中的部分图片是有一定旋转角度的，因此随机旋转符合该数据集的特点。但是由于是数字识别，<strong>旋转角度不可以太大</strong>，我们使用的是torchvision中的RandomRotation()，限定在-10°~10°之间随机旋转。<br><br>  <img alt="mcharlog/图像模糊.bmp" src="assets/mchar-log/0.001+0.0001+weight+data10.bmp" width="700" height=""><br><br>  随机旋转可以提高1个点，最后val_acc稳定在0.60级别。<br></p>  <img alt="assets/mchar-lossacc/图像模糊/val_loss.svg" src="assets/mchar-lossacc/0.01+0.001+weight+data10度/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/图像模糊/val_acc.svg" src="assets/mchar-lossacc/0.01+0.001+weight+data10度/val_acc.svg" width="350" height=""><br>  最后val_loss和val_acc都比较平稳，波动幅度小。</li><li><p><strong>平移</strong><br><br>  位置变换是十分有效的数据增强手段，由于本赛题数字字符识别的特点，无法使用镜像等操作，所以我们使用左右和上下平移来进行位置增强。<br><br>  需要说明的是，<strong>本赛题的学习任务对于位置信息很敏感</strong>，尤其是左右位置，因为需要网络学习第1个字符的位置。而数据集图片中的字符位置没有对齐，可能偏左，可能偏右，可能居中。所以通过平移进行位置增强，使得模型适应不同起始位置的字符提取。<br><br>  通过随机选择数据集中的样本进行左右和上下偏移，我们发现将图片resize到（64,128），左右偏移量(-35，35)，上下偏移量（-10，10）是合适的。可以起到位置偏移的增强，且不会影响到数字识别。<br><br>  <img alt="mcharlog/图像模糊.bmp" src="assets/mchar-log/offset.bmp" width="700" height=""><br><br>  通过位置偏移，val_acc可以涨1-2个点，0.60-&gt;0.61/0.62。最后val_acc在0.61到0.62之间波动。<br></p>  <img alt="assets/mchar-lossacc/offset/val_loss.svg" src="assets/mchar-lossacc/offset/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/offset/val_acc.svg" src="assets/mchar-lossacc/offset/val_acc.svg" width="350" height=""><br>  val_loss最终在1.60-1.70之间波动。</li></ul></li><li><p><strong>数据增强总结</strong><br><br>通过上面单一变量分析和对比实验，我们发现<strong>图像模糊和位置平移十分适合本赛题的学习任务和数据集特点</strong>。<br><br>最后，我们把光学变换、图像模糊、随机旋转和随机位置平移综合到一起，进行数据增强。<br><br><img alt="mcharlog/offset+模糊.bmp" src="assets/mchar-log/offset+模糊.bmp" width="700" height=""><br><br>val_acc可以稳定在0.62，甚至达到0.63（epoch26）。<br></p><img alt="assets/mchar-lossacc/offset/val_loss.svg" src="assets/mchar-lossacc/offset+模糊/val_loss.svg" width="340" height=""><img alt="assets/mchar-lossacc/offset/val_acc.svg" src="assets/mchar-lossacc/offset+模糊/val_acc.svg" width="340" height=""><br>val_loss最终在1.50-1.60之间波动缓慢下降，val_acc在0.62-0.63之间缓慢上升。<br>val_loss的过拟合通过数据增强降低了，val_acc缓慢上升。可以在上图的基础上继续训练多个epoch，看val_loss是否有明显下降，val_acc是否有明显上升（估计不会了）。由于时间有限，我没有继续往下训练。</li></ul><h3 id="ResNet34"><a href="#ResNet34" class="headerlink" title="ResNet34"></a>ResNet34</h3><p>基于上面ResNet18网络进行各种单一变量实验和综合实验的结果，我们进一步增大模型的复杂度，使用ResNet34的预训练模型，期望获得val_acc精度的提高。</p><ul><li><p><strong>数据增强</strong><br><br>数据增强的手段和上面最后一小结使用的数据增强手段相同，随机裁剪、光学变换、图像模糊、随机旋转和随机位置平移。</p></li><li><p><strong>学习率调节</strong><br><br>为了缩短训练时间，我们采用断点续训的方式来调节不同阶段的学习率，即保存每个epoch下的checkpoint，主要是模型的参数和优化器参数，然后选择某个节点的checkpoint继续训练。<br></p><ul><li><p><strong>一阶学习率</strong></p><ul><li><strong>lr = 0.01</strong><br><br>  <img alt="mcharlog/resnet34-0.01.bmp" src="assets/mchar-log/resnet34-0.01.bmp" width="700" height=""><br><br>  ResNet34比ResNet18更难训练。<br><br>  ResNet18在学习率0.01情况下， Adam用了3个epoch进行学习率自适应调节，在第4个epoch后val_acc从0.1开始快速上升。<br><br>  ResNet34在初始学习率为0.01的情况下，进行了10个epoch的训练，都没有将val_loss降低（还是5.1-5.2级别），没有将val_acc提高（还是0.01级别）。所以0.01的初始学习率对于ResNet34太大了。</li><li><strong>lr = 0.001</strong><br><br>  <img alt="mcharlog/resnet34-0.001.bmp" src="assets/mchar-log/resnet34-0.001.bmp" width="700" height=""><br><br>  【第一次实验】我们发现前5个epoch，val_loss没有快速下降，而是在5.1-5.3之间波动，val_acc没有快速上升，而是在0.01-0.05之间缓慢上升。<br><br>  <strong>ResNet34比ResNet18更难训练</strong>，在学习率0.001情况下，Adam用了6个epoch进行学习率的自适应调节，在第6个epoch后，val_acc从0.1开始快速上升。<br></li></ul><p>  【第二次实验】我们发现0.001的学习率训练了10个epoch后，val_loss开始快速下降，val_acc快速上升，且没有过拟合趋势，所以继续以0.001的学习率训练了5个epoch。此时，val_loss从3.1下降到了2.5，val_acc从0.4上升到了0.5，提高了10个点。<br></p><p>  【第三次实验】由于上面的5个epoch中，val_loss在下降，val_acc在快速上升，没有过拟合趋势。所以还是以0.001的学习率继续训练10个epoch。发现val_loss从2.5降低到了2.3，val_acc从0.50提高到了0.53。尽管val_acc有提高，但是提高比较缓慢，可以使用0.001的学习率，但是为了加快收敛速度，我们决定使用二阶学习率0.0001。<br></p><p>  【第四次实验-二阶学习率】我们在第二次实验的5个epoch后，改用0.0001的二阶学习率训练了10个epoch。可以发现val_loss从2.2降低到1.9，val_acc从0.50突增到0.59，一个epoch增加了9个点。此后val_loss从1.9缓慢降低到1.7，val_acc从0.59缓慢提高到0.61。<br></p><p>  【第五次实验-三阶学习率】然后改用0.00001的三阶学习率继续训练了20个epoch。<br><br>  <img alt="mcharlog/resnet34-0.001-三阶学习率.bmp" src="assets/mchar-log/resnet34-0.001-三阶学习率.bmp" width="700" height=""><br><br>  val_loss在1.7附近波动，val_acc从0.61提高到0.62，提升了1个点。</p></li></ul></li><li><p><strong>总结</strong><br><br>我们发现更换了更复杂的模型，训练更难了，但是最后的val_acc没有获得提高，还是0.62级别。<br><br>下面决定换其他思路来解决这个赛题。</p></li></ul><h3 id="改变学习任务：4字符"><a href="#改变学习任务：4字符" class="headerlink" title="改变学习任务：4字符"></a>改变学习任务：4字符</h3><p>baseline固定的字符长度是5，但是在随机查看训练集图片是，几乎没有发现字符长度是5的样本。我统计了一下训练集中的样本的字符长度，字符长度为1：2：3：4：5：6的样本数量为4636：16262：7813：1280：8：1。所以，我决定把字符长度固定为4。<br><br>固定字符长度为5，意味着很多图片都需要学习后2个或后3个字符为X（空，非0-9字符），而这个预测过程是容易出错的。<br><br>我们把字符长度固定为4，就是直接预测错误8个5字符样本和1个6字符样本，但是同时由于大多数的1字符、2字符和3字符样本，需要预测的X字符少了很多，所以可以降低后几位预测X字符的错误，预期可以提高val_acc。<br></p><ul><li><p><strong>数据增强</strong><br><br>和上面使用的数据增强手段相同。随机裁剪、光学变换、图像模糊、随机旋转和随机位置平移。</p></li><li><p><strong>学习率调节</strong><br><br>使用的网络是ResNet34。</p><ul><li><p><strong>一阶学习率 lr = 0.001</strong><br><br>  由于上面有ReSNet34训练的经验，所以直接在一阶学习率使用0.001。<br><br>  <img alt="mcharlog/4字节.bmp" src="assets/mchar-log/4字节.bmp" width="700" height=""><br></p>  <img alt="assets/mchar-lossacc/4字节/val_loss.svg" src="assets/mchar-lossacc/4字节/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/4字节/val_acc.svg" src="assets/mchar-lossacc/4字节/val_acc.svg" width="350" height=""><br>  训练了15个epoch，val_loss从5.1降低到2.5，val_acc从0.2快速上升到0.56。</li><li><p><strong>二阶学习率 lr = 0.001</strong><br><br>  由于一阶学习中val_loss在下降，val_acc在上升，没有看到明显的过拟合现象，所以这里继续使用0.001的学习率训练10个epoch。<br><br>  <img alt="mcharlog/4字节-2-0.001.bmp" src="assets/mchar-log/4字节-2-0.001.bmp" width="700" height=""><br><br>  此时，val_loss从2.7增加到3.2，val_acc稳定在0.56附近，这是明显的过拟合现象。所以，下面决定在二阶学习率降低为10%，使用0.0001。</p></li><li><p><strong>二阶学习率 lr = 0.0001</strong><br><br>  使用0.0001学习率，训练了15个epoch。<br>  <img alt="mcharlog/4字节-2-0.0001.bmp" src="assets/mchar-log/4字节-2-0.0001.bmp" width="700" height=""><br></p>  <img alt="assets/mchar-lossacc/4字节-2-0.0001/val_loss.svg" src="assets/mchar-lossacc/4字节-2-0.0001/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/4字节-2-0.0001/val_acc.svg" src="assets/mchar-lossacc/4字节-2-0.0001/val_acc.svg" width="350" height="">  val_loss从2.3降低到2.0，val_acc从0.56快速上升到0.61（1个epoch，二阶学习率下降的效果），然后从0.61缓慢上升到0.64。<br></li><li><p><strong>三阶学习率 lr = 0.0001</strong><br><br>  由于二阶段学习中，val_loss在下降，val_acc在上升，没有看到明显的过拟合现象。所以这里仍然使用0.0001的学习率训练了20个epoch。<br><br>  <img alt="mcharlog/4字节-3-0.0001.bmp" src="assets/mchar-log/4字节-3-0.0001.bmp" width="700" height=""><br><br>  val_loss在2.2和2.3之间波动，没有明显下降趋势，val_acc在0.64级别波动，没有明显上升趋势。说明此时学习率已经不合适，偏大。<br></p></li><li><p><strong>三阶学习率 lr = 0.00001</strong><br><br>  把三阶学习率调节为二阶学习率的10%，为0.00001，训练15个epoch。<br>  <img alt="mcharlog/4字节-3-0.00001.bmp" src="assets/mchar-log/4字节-3-0.00001.bmp" width="700" height=""><br></p>  <img alt="assets/mchar-lossacc/4字节-3-0.00001/val_loss.svg" src="assets/mchar-lossacc/4字节-3-0.00001/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/4字节-3-0.00001/val_acc.svg" src="assets/mchar-lossacc/4字节-3-0.00001/val_acc.svg" width="350" height=""><br>  val_loss从2.2缓慢下降到2.0, val_acc从0.64缓慢上升到0.65，稳定在0.65。说明这个学习率是合适的。</li></ul></li><li><p><strong>总结</strong><br><br>改变学习任务后，val_acc从0.62提高到0.65，提高了3个点。<br><br>说明把学习任务改为预测4字符后，学习难度下降了。原来的学习任务是预测5字符，很多2字符、3字符样本需要预测很多后几位的X字符（空字符，非0-9）,这个预测过程容易出错。 现在预测4字符，需要预测的后面的空字符个数少了，从而降低了出错概率，提高了val_acc。</p></li></ul><h3 id="改变数据集：样本加权"><a href="#改变数据集：样本加权" class="headerlink" title="改变数据集：样本加权"></a>改变数据集：样本加权</h3><p>通过查看提交的测试集预测结果，人工查验了一下测试集前100个样本和前100个预测结果，发现了一个明显的主要出错现象-3字符样本的预测结果容易丢最后一个字符，即把3字符样本的第3位预测为X空字符，从而预测结果是2位，预测错误。<br><br>前100个样本中，一共预测错误19个，其中字符预测出错7个，字符丢失出错10个（2字符样本丢失第2位出错2个，3字符样本丢失第3位出错8个）。<br><br>下面主要围绕3字符样本丢失第3位的问题进行解决。</p><ul><li><p><strong>解决方法</strong><br></p><ul><li>损失加权。baseline中的4个字符的预测损失直接相加，权重是1：1：1：1，为了提高第1个字符的预测位置准确度和第3个字符的预测准确度，把4个字符的损失加权求和，权重为2：1：2：1。</li><li>样本加权。通过上面的统计，看到3字符样本7813，总共的训练集样本数30000。为了增大3字符样本的训练量，在构建train_img_path和train_label_path时，如果样本的字符长度是3，就append两次。从而3字符样本数量增大一倍。</li><li>增加预测分支。本来的CNN后连接4个全连接层，分别预测第1、2、3、4个字符的类别。可以增加第5个全连接层，预测每个样本中的字符个数。根据预测的字符个数，提高最终字符串预测结果的准确度。<br></li></ul></li><li><p><strong>数据增强</strong><br><br>数据增强的手段和上面使用的数据增强手段相同，随机裁剪、光学变换、图像模糊、随机旋转和随机位置平移。<br><br>对样本进行加权，使得3字符样本数量增大了一倍。</p></li><li><p><strong>学习率调节</strong><br><br>使用的网络是ResNet34。</p><ul><li><p><strong>一阶学习率 lr = 0.001</strong><br><br>  根据上面的经验，一阶学习率是0.001，训练了15个epoch。<br><br>  <img alt="mcharlog/数据加权.bmp" src="assets/mchar-log/数据加权.bmp" width="700" height=""><br></p>  <img alt="assets/mchar-lossacc/数据加权/val_loss.svg" src="assets/mchar-lossacc/数据加权/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/数据加权/val_acc.svg" src="assets/mchar-lossacc/数据加权/val_acc.svg" width="350" height=""><br>  val_loss从5.5减低到3.1，val_acc从0.25提高到0.57。</li><li><p><strong>二阶学习率 lr = 0.001</strong><br><br>  由于一阶学习中的val_loss仍然在下降，val_acc仍然在上升，所以继续使用0.001的学习率训练10个epoch。<br><br>  <img alt="mcharlog/数据加权-2-0.001.bmp" src="assets/mchar-log/数据加权-2-0.001.bmp" width="700" height=""><br></p>  <img alt="assets/mchar-lossacc/数据加权-2-0.001/val_loss.svg" src="assets/mchar-lossacc/数据加权-2-0.001/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/数据加权-2-0.001/val_acc.svg" src="assets/mchar-lossacc/数据加权-2-0.001/val_acc.svg" width="350" height=""><br>  val_loss从3.5降低到3.0,val_acc从0.56上升到0.60。</li><li><p><strong>三阶梯学习率 lr = 0.001</strong><br><br>  由于二阶学习中的val_loss在下降，val_acc在上述，没有明显的过拟合现象，所以仍然使用0.001的学习率训练10个epoch。<br><br>  <img alt="mcharlog/数据加权-3-0.001.bmp" src="assets/mchar-log/数据加权-3-0.001.bmp" width="700" height=""><br><br>  此时，val_loss在3.0-3.5之间波动，val_acc在0.58-0.60之间波动。由于波动，说明此时学习率已经不合适了，偏大，下面降低学习率进行实验。</p></li><li><p><strong>三阶学习率 lr = 0.0001</strong><br><br>  下面降低学习率为0.0001的二阶学习率训练了15个epoch。<br><br>  <img alt="mcharlog/数据加权-3-0.0001.bmp" src="assets/mchar-log/数据加权-3-0.0001.bmp" width="700" height=""><br></p>  <img alt="assets/mchar-lossacc/数据加权-3-0.0001/val_loss.svg" src="assets/mchar-lossacc/数据加权-3-0.0001/val_loss.svg" width="350" height="">  <img alt="assets/mchar-lossacc/数据加权-3-0.0001/val_acc.svg" src="assets/mchar-lossacc/数据加权-3-0.0001/val_acc.svg" width="350" height=""><br>  val_loss在2.7-3.1之间波动，val_acc首先快速上升到0.63（1个epoch突然上升，学习率阶段降低的效果），然后从0.63缓慢上升到0.65。</li><li><p><strong>四阶学习率 lr = 0.0001</strong><br><br>  依然以0.0001的学习率训练了10个epoch。<br>  <img alt="mcharlog/数据加权-4-0.0001.bmp" src="assets/mchar-log/数据加权-4-0.0001.bmp" width="700" height=""><br><br>  val_loss在3.0附近波动，val_acc稳定在0.65，没有明显上升趋势。可能是学习率较大，下面降低学习率。</p></li><li><p><strong>四阶学习率 lr = 0.00001</strong><br><br>  降低学习率，以0.00001的学习率继续训练了20个epoch。<br><br>  <img alt="mcharlog/数据加权-4-0.00001.bmp" src="assets/mchar-log/数据加权-4-0.00001.bmp" width="700" height=""><br><br>  val_loss在3.0附近波动，val_acc稳定在0.65级别，没有明显上升。</p></li></ul></li><li><p><strong>总结</strong><br><br>我们发现了出错的一个主要问题，3字符样本丢失第3位。采用的解决方法是损失加权，加大第1个字符和第3个字符的损失权重。样本加权，加大3字符样本数量一倍。<br><br>由于时间有限，我还没有尝试第3种解决方法-增加预测分支，预测样本的字符个数。<br><br>遗憾的是，最终的val_acc还是在0.65级别，没有提高。已经找到了问题的所在，但是没有解决好。</p></li></ul><h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><ul><li><p><strong>总结前面</strong></p><ul><li>整个训练过程我们都是使用3阶段下降学习率（每个阶段的学习率是前一个阶段的10%），包括后面的SSD分支中SGD优化器也是使用3阶段下降学习率。</li><li>ResNet18上通过对数据增强手段的单一变量实现，筛选最合适的数据增强手段。最终利用丰富的数据增强手段，提高3个点0.59-&gt;0.62。</li><li>ResNet34比ResNet18难训练，使用相同的数据增强手段和三阶学习率，最后的val_acc还是0.62级别。</li><li>改变学习任务：4字符。可以提高3个点，0.62-&gt;0.65。依然使用三阶学习率和相同的数据增强。</li><li>改变数据集：样本加权。可以提高3个点，0.62-&gt;0.65。这三个点还是改变学习任务中获得的，所以仍然没有解决3字符样本丢失第3个字符的问题。</li><li>在掌握了<strong>基本的网络模型，阶段学习率下降，数据增强等常用训练手段</strong>后。提高精度的一个重要角度是<strong>认真分析赛题任务特点，数据集特点，分析测试集主要出错点</strong>。根据本赛题独有的特点，针对性的改进模型，改进训练过程等。<br><br>  例如本赛题数字字符串预测，不可镜像，旋转角度小，对位置敏感。本数据集图片分辨率低，统计字符长度，5字符和6字符数据很少，可以忽略。测试集出错的主要原因是3字符样本第3个字符丢失。</li></ul></li><li><p><strong>集成学习</strong><br><br>前面的实验致力于提高单模型的预测精度。下面可以利用集成学习提高总的预测结果的准确率。<br><br>集成学习的思路是不推荐的，我们致力于提高单模型的预测精度。因为集成学习的效果是很好的，多个较差的独立基模型集成学习结果，可以有较大提高。<br><br>集成学习对于学习本身，赛题本身是没有太大意义的。而且比赛中会限制模型大小和推理时间，如果使用多个模型进行集成，会增大模型大小和推理时间。</p><ul><li><p>Bagging<br><br>  训练多个不同的模型，每个模型之间的尽量独立，对数据集进行随机采样来训练多个模型。最后通过投票的方法进行模型集成。例如多折交叉验证。<br><br>  上面单模型中最好的两个结果是val_acc为0.65，测试集预测后提交score是0.77-0.78左右（因为测试集样本稍微简单一些）。一个最好的结果分别是改变学习任务后训练的结果。另一个最好的结果是改变数据样本分布后训练的结果。这两个模型之间还是有一些差异的，因为改变了数据的样本分布。<br><br>  用这两个模型预测结果的平均作为集成学习的结果，提交网站后，score为0.81。可见集成学习效果是很好的。<br><br>  我只是用了两个模型进行集成学习，如果集成更多的差异性模型，会获得更好的结果。但是不推荐集成学习，还是致力于提高单模型的精度。</p></li><li><p>随机森林<br><br>  随机森林在Bagging基础上引入随机特征，进一步提高每个基模型之间的独立性。</p></li><li><p>Boosting<br><br>  按照一定的顺序先后训练不同的基模型，每个基模型都根据前序模型的错误进行专门训练。Boosting集成学习的效果很好。</p></li><li><p>TTA<br><br>  测试集数据增强，就是单个模型对测试集进行多次预测，多个预测结果平均，得到最后的结果。<br><br>  我进行了TTA 10次，对比测试集前100个样本和预测结果，发现结果并没有提高。该模型一次预测出错的样本，10次预测结果的平均还是出错。所以一个模型的弱点，在多次预测后平均，这个弱点还是无法弥补的。需要其他不同的模型来弥补。</p></li></ul></li></ul><h3 id="SSD-目标检测"><a href="#SSD-目标检测" class="headerlink" title="SSD 目标检测"></a>SSD 目标检测</h3><ul><li><p><strong>训练</strong><br><br>batch_size=16，训练了30000个iterator。使用的是SDG优化器，初始学习率是0.001，15000个iterator后，学习率降低为10倍，为0.0001；25000个iterator后，学习率降低10倍，为0.00001。优化器使用的动量系数是0.9，正则化系数为0.0005。<br></p><img alt="assets/SSD_train_loss_iterator.svg" src="assets/SSD_train_loss_iterator.svg" width="400" height=""><img alt="assets/SSD_train_loss_epoch.svg" src="assets/SSD_train_loss_epoch.svg" width="400" height=""><br>左图是train_loss，横坐标是iterator。右图是train_loss，横坐标是epoch。<br>30000个iterator训练后，总的train_loss降低到2.0~2.1级别。</li><li><p><strong>验证</strong><br></p></li><li><p><strong>测试</strong><br></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 随笔 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>django安装使用</title>
      <link href="/2020/01/14/django-an-zhuang-shi-yong/"/>
      <url>/2020/01/14/django-an-zhuang-shi-yong/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> django </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-10-17数据操作</title>
      <link href="/2020/01/14/2022-10-17-shu-ju-cao-zuo/"/>
      <url>/2020/01/14/2022-10-17-shu-ju-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>从MXNet导入ndarray模块</p><pre><code class="javascript">from mxnet import ndx = nd.arange(a)</code></pre><p>通过shape属性获取实例的形状</p><pre><code class="javascript">x.shape</code></pre><p>通过size获取实例中元素的总数</p><pre><code class="javascript">x.size</code></pre><p>使用reshape函数改变实例的形状</p><pre><code class="javascript">X = x.reshape((a,b))</code></pre><p>创建各元素为1的张量，为2的张量</p><pre><code class="javascript">nd.ones((a,b))nd.twos((a,b))</code></pre><p>指定实例中每个元素的值</p><pre><code class="javascript">Y = nd.array([a,b,c],[q,w,e],[t,y,u])</code></pre><h3 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h3><p>两个不同的实例按元素运算时，可能会触发广播机制：先复制元素使形状相同后在运算。</p><pre><code class="javascript">A = nd.arange(3).reshape((3, 1)) B = nd.arange(2).reshape((1, 2)) A, B Out[19]: ( [[0.] [1.] [2.]] &lt;NDArray 3x1 @cpu(0)&gt;, [[0. 1.]] &lt;NDArray 1x2 @cpu(0)&gt;)A+B[[0. 1.] [1. 2.] [2. 3.]] &lt;NDArray 3x2 @cpu(0)&gt;</code></pre><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>行索引截取：[a:b]<br>指定访问元素的位置，并重新赋值：X[a,b]=number</p><h3 id="运算的内存开销"><a href="#运算的内存开销" class="headerlink" title="运算的内存开销"></a>运算的内存开销</h3><p>id函数：</p><pre><code class="javascript">before = id(Y) Y=Y+X id(Y) == beforeFalse</code></pre><p>指定结果到特定内存：（开辟了临时内存存储计算结果）</p><pre><code class="javascript">Z = Y.zeros_like() before = id(Z)Z[:] = X + Yid(Z) == beforeTrue</code></pre><p>避免临时内存开销，使用out函数：</p><pre><code class="javascript">nd.elemwise_add(X, Y, out=Z) id(Z) == beforeTrue</code></pre><h3 id="NDArray和Numpy相互变换"><a href="#NDArray和Numpy相互变换" class="headerlink" title="NDArray和Numpy相互变换"></a>NDArray和Numpy相互变换</h3><p>将NumPy实例变换成NDArray实例</p><pre><code class="javascript">import numpy as np P = np.ones((2, 3)) D = nd.array(P) D[[1. 1. 1.] [1. 1. 1.]] &lt;NDArray 2x3 @cpu(0)&gt;</code></pre><p>将NDArray实例变换成NumPy实例</p><pre><code class="javascript">D.asnumpy()array([[1., 1., 1.], [1., 1., 1.]], dtype=float32)</code></pre><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>• NDArray是MXNet中存储和变换数据的主要工具。<br>• 可以轻松地对NDArray创建、运算、指定索引，并与NumPy之间相互变换。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022-10-17自动求梯度</title>
      <link href="/2020/01/14/2022-10-17-zi-dong-qiu-ti-du/"/>
      <url>/2020/01/14/2022-10-17-zi-dong-qiu-ti-du/</url>
      
        <content type="html"><![CDATA[<p>导入模块：</p><pre><code class="javascript">from mxnet import autograd, nd</code></pre><p>先调用attach_grad函数来申请存储梯度所需要的内存</p><pre><code class="javascript">x.attach_grad()</code></pre><p>默认条件下MXNet不会记录用于求梯度 的计算。我们需要调用record函数来要求MXNet记录与求梯度有关的计算。</p><pre><code class="javascript">with autograd.record():         y = 2 * nd.dot(x.T, x)</code></pre><p>通过调用backward函数自动求梯度</p><pre><code class="javascript">y.backward()</code></pre><p>例子：<br>函数 y = 2x⊤x 关于x 的梯度应为4x。现在我们来验证一下求出来的梯度是正确的</p><pre><code class="javascript">x = nd.arange(4).reshape((4, 1))x.attach_grad()with autograd.record():    y = 2 * nd.dot(x.T, x)y.backward()assert (x.grad - 4 * x).norm().asscalar() == 0 print(x.grad)[[ 0.][ 4.][ 8.][12.]] &lt;NDArray 4x1 @cpu(0)&gt;</code></pre><h3 id="训练模式和预测模式"><a href="#训练模式和预测模式" class="headerlink" title="训练模式和预测模式"></a>训练模式和预测模式</h3><p>在调用record函数后，MXNet会记录并计算梯度。此外，默认情况下autograd还会将运行模式从预测模式转为训练模式。这可以通过调用is_training函数来查看。</p><pre><code class="javascript">print(autograd.is_training())with autograd.record():    print(autograd.is_training())        False    True</code></pre><h3 id="python控制流求梯度"><a href="#python控制流求梯度" class="headerlink" title="python控制流求梯度"></a>python控制流求梯度</h3><p>使用MXNet的一个便利之处是，即使函数的计算图包含了Python的控制流(如条件和循环控制)，我们也有可能对变量求梯度。<br>考虑下⾯程序，其中包含Python的条件和循环控制。需要强调的是，这⾥循环（while循环）迭代的次数和条件判断（if语句）的执⾏都取决于输⼊a的值。</p><pre><code class="javascript">def f(a):    b = a * 2    while b.norm().asscalar() &lt; 1000:        b = b * 2    if b.sum().asscalar() &gt; 0:        c = b    else:        c = 100 * b    return ca = nd.random.normal(shape=1)a.attach_grad()with autograd.record():    c = f(a)c.backward()print(a.grad)print(c/a)</code></pre><p><img src="/./images/v2-027f25a1ae5d34300a7536897802827c_720w.jpg" alt="enter description here"></p><p>分析一下，上面定义的f函数。事实上，给定任意输入a，其输出必然是f(a) = x*a的形式，其中标量系数x的值取决于输入a。由于c = f(a)有关a的梯度为x，且值为c/a，我们可以像下面这样验证本例中控制流求梯度的结果的正确性。</p><pre><code class="javascript">a.grad == c / a[1.] &lt;NDArray 1 @cpu(0)&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 笔记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
